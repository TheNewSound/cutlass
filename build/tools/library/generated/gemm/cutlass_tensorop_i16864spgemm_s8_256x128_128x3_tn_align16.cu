
/*
  Generated by gemm_operation.py - Do not edit.
*/

///////////////////////////////////////////////////////////////////////////////////////////////////
#include "cutlass/arch/wmma.h"
#include "cutlass/cutlass.h"
#include "cutlass/library/library.h"
#include "cutlass/library/manifest.h"

#include "library_internal.h"
#include "gemm_operation.h"

///////////////////////////////////////////////////////////////////////////////////////////////////


  // Gemm operator cutlass_tensorop_i16864spgemm_s8_256x128_128x3_tn_align16
  using Operation_cutlass_tensorop_i16864spgemm_s8_256x128_128x3_tn_align16 = cutlass::gemm::device::SparseGemm<
    int8_t, cutlass::layout::RowMajor,
    int8_t, cutlass::layout::ColumnMajor,
    int32_t, cutlass::layout::RowMajor,
    int32_t,
    cutlass::arch::OpClassTensorOp,
    cutlass::arch::Sm80,
    cutlass::gemm::GemmShape<256, 128, 128>,
    cutlass::gemm::GemmShape<64, 64, 128>,
    cutlass::gemm::GemmShape<16, 8, 64>,
    cutlass::epilogue::thread::LinearCombinationClamp<
      int32_t,
      4,
      int32_t,
      int32_t
    >,
    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
    3,
    16,
    16,
    false,
    cutlass::arch::OpMultiplyAddSaturate
    
  >;


///////////////////////////////////////////////////////////////////////////////////////////////////

namespace cutlass {
namespace library {

///////////////////////////////////////////////////////////////////////////////////////////////////

void initialize_cutlass_tensorop_i16864spgemm_s8_256x128_128x3_tn_align16(Manifest &manifest) {



  manifest.append(new GemmSparseOperation<Operation_cutlass_tensorop_i16864spgemm_s8_256x128_128x3_tn_align16>("cutlass_tensorop_i16864spgemm_s8_256x128_128x3_tn_align16"));



}

///////////////////////////////////////////////////////////////////////////////////////////////////

} // namespace library
} // namespace cutlass

///////////////////////////////////////////////////////////////////////////////////////////////////

